version: '3.9'
services:
  configurator:
    depends_on:
      - mongodb
      - zookeeper
      - kafka
      - temporal
    deploy:
      restart_policy:
        condition: on-failure
        delay: 3s
        max_attempts: 5
        window: 60s
    build:
      context: .
      dockerfile: ./apps/configurator/Dockerfile
    expose:
      - 8080
    ports:
      - 9000:8080
    volumes:
      - ./apps/configurator/client.key:/app/client.key
      - ./apps/configurator/client.pem:/app/client.pem
    environment:
      - NODE_ENV=development
      - PORT=8080
      - API_KEYS=${API_KEYS}
      - DB_TYPE=mongodb
      - DB_URI=${DB_URI}
      - DEST_DB_URI=${DEST_DB_URI}
      - BROKER_TYPE=kafka
      - BROKER_URIS=${BROKER_URIS}
      - KAFKA_CLIENT_ID=configurator
      - KAFKA_CONSUMER_GROUP_ID=configurator-consumer
      - KAFKA_SSL_ENABLED=${KAFKA_SSL_ENABLED}
      - KAFKA_SASL_ENABLED=${KAFKA_SASL_ENABLED}
      - KAFKA_SASL_USERNAME=${KAFKA_SASL_USERNAME}
      - KAFKA_SASL_PASSWORD=${KAFKA_SASL_PASSWORD}
      - ORCHESTRATOR_ADDRESS=${ORCHESTRATOR_ADDRESS}
      - ORCHESTRATOR_NAMESPACE=${ORCHESTRATOR_NAMESPACE}
      - ORCHESTRATOR_WORKER_TASKQUEUE=configurator
      - ORCHESTRATOR_DEFAULT_TASKQUEUE=configurator
      - ORCHESTRATOR_TLS_ENABLED=${ORCHESTRATOR_TLS_ENABLED}
      - ORCHESTRATOR_CLIENT_CERT=${ORCHESTRATOR_CLIENT_CERT}
      - ORCHESTRATOR_CLIENT_KEY=${ORCHESTRATOR_CLIENT_KEY}
      - MICROSOFT_CLIENT_ID=${MICROSOFT_CLIENT_ID}
      - MICROSOFT_CLIENT_SECRET=${MICROSOFT_CLIENT_SECRET}
      - GOOGLE_CLIENT_ID=${GOOGLE_CLIENT_ID}
      - GOOGLE_CLIENT_SECRET=${GOOGLE_CLIENT_SECRET}
  controller:
    depends_on:
      - mongodb
      - zookeeper
      - kafka
      - temporal
    deploy:
      restart_policy:
        condition: on-failure
        delay: 3s
        max_attempts: 5
        window: 60s
    build:
      context: .
      dockerfile: ./apps/controller/Dockerfile
    expose:
      - 8080
    ports:
      - 9001:8080
    environment:
      - NODE_ENV=development
      - PORT=8080
      - DB_TYPE=mongodb
      - DB_URI=${DB_URI}
      - BROKER_TYPE=kafka
      - BROKER_URIS=${BROKER_URIS}
      - KAFKA_CLIENT_ID=controller
      - KAFKA_CONSUMER_GROUP_ID=controller-consumer
      - KAFKA_SSL_ENABLED=${KAFKA_SSL_ENABLED}
      - KAFKA_SASL_ENABLED=${KAFKA_SASL_ENABLED}
      - KAFKA_SASL_USERNAME=${KAFKA_SASL_USERNAME}
      - KAFKA_SASL_PASSWORD=${KAFKA_SASL_PASSWORD}
      - ORCHESTRATOR_ADDRESS=${ORCHESTRATOR_ADDRESS}
      - ORCHESTRATOR_NAMESPACE=${ORCHESTRATOR_NAMESPACE}
      - ORCHESTRATOR_WORKER_TASKQUEUE=controller
      - ORCHESTRATOR_DEFAULT_TASKQUEUE=controller
      - ORCHESTRATOR_TLS_ENABLED=${ORCHESTRATOR_TLS_ENABLED}
      - ORCHESTRATOR_CLIENT_CERT=${ORCHESTRATOR_CLIENT_CERT}
      - ORCHESTRATOR_CLIENT_KEY=${ORCHESTRATOR_CLIENT_KEY}
      - MICROSOFT_CLIENT_ID=${MICROSOFT_CLIENT_ID}
      - MICROSOFT_CLIENT_SECRET=${MICROSOFT_CLIENT_SECRET}
      - GOOGLE_CLIENT_ID=${GOOGLE_CLIENT_ID}
      - GOOGLE_CLIENT_SECRET=${GOOGLE_CLIENT_SECRET}
      - IGNORE_WORKFLOW_TRIGGERED=false
  worker:
    depends_on:
      - mongodb
      - zookeeper
      - kafka
      - temporal
    deploy:
      restart_policy:
        condition: on-failure
        delay: 3s
        max_attempts: 5
        window: 60s
    build:
      context: .
      dockerfile: ./apps/worker/Dockerfile
    expose:
      - 8080
    ports:
      - 9003:8080
    environment:
      - NODE_ENV=development
      - PORT=9000
      - DB_TYPE=mongodb
      - DB_URI=${DB_URI}
      - BROKER_TYPE=kafka
      - BROKER_URIS=${BROKER_URIS}
      - KAFKA_CLIENT_ID=worker
      - KAFKA_CONSUMER_GROUP_ID=worker-consumer
      - KAFKA_SSL_ENABLED=${KAFKA_SSL_ENABLED}
      - KAFKA_SASL_ENABLED=${KAFKA_SASL_ENABLED}
      - KAFKA_SASL_USERNAME=${KAFKA_SASL_USERNAME}
      - KAFKA_SASL_PASSWORD=${KAFKA_SASL_PASSWORD}
      - ORCHESTRATOR_ADDRESS=${ORCHESTRATOR_ADDRESS}
      - ORCHESTRATOR_NAMESPACE=${ORCHESTRATOR_NAMESPACE}
      - ORCHESTRATOR_WORKER_TASKQUEUE=worker
      - ORCHESTRATOR_DEFAULT_TASKQUEUE=worker
      - ORCHESTRATOR_TLS_ENABLED=${ORCHESTRATOR_TLS_ENABLED}
      - ORCHESTRATOR_CLIENT_CERT=${ORCHESTRATOR_CLIENT_CERT}
      - ORCHESTRATOR_CLIENT_KEY=${ORCHESTRATOR_CLIENT_KEY}
      - DOWNLOADER_URL=http://downloader:8080
      - COMPARER_URL=http://comparer:8080
      - LOADER_URL=http://loader:8080
      - PROCESSOR_API_KEY=${WORKER_PROCESSOR_API_KEY}
      - MICROSOFT_CLIENT_ID=${MICROSOFT_CLIENT_ID}
      - MICROSOFT_CLIENT_SECRET=${MICROSOFT_CLIENT_SECRET}
      - GOOGLE_CLIENT_ID=${GOOGLE_CLIENT_ID}
      - GOOGLE_CLIENT_SECRET=${GOOGLE_CLIENT_SECRET}
  post-processor:
    depends_on:
      - mongodb
      - zookeeper
      - kafka
      - temporal
    deploy:
      restart_policy:
        condition: on-failure
        delay: 3s
        max_attempts: 5
        window: 60s
    build:
      context: .
      dockerfile: ./apps/post-processor/Dockerfile
    expose:
      - 8080
    ports:
      - 9004:8080
    environment:
      - NODE_ENV=development
      - PORT=9000
      - DB_TYPE=mongodb
      - DB_URI=${DB_URI}
      - BROKER_TYPE=kafka
      - BROKER_URIS=${BROKER_URIS}
      - KAFKA_CLIENT_ID=post-processor
      - KAFKA_CONSUMER_GROUP_ID=post-processor-consumer
      - KAFKA_SSL_ENABLED=${KAFKA_SSL_ENABLED}
      - KAFKA_SASL_ENABLED=${KAFKA_SASL_ENABLED}
      - KAFKA_SASL_USERNAME=${KAFKA_SASL_USERNAME}
      - KAFKA_SASL_PASSWORD=${KAFKA_SASL_PASSWORD}
      - ORCHESTRATOR_ADDRESS=${ORCHESTRATOR_ADDRESS}
      - ORCHESTRATOR_NAMESPACE=${ORCHESTRATOR_NAMESPACE}
      - ORCHESTRATOR_WORKER_TASKQUEUE=post-processor
      - ORCHESTRATOR_DEFAULT_TASKQUEUE=post-processor
      - ORCHESTRATOR_TLS_ENABLED=${ORCHESTRATOR_TLS_ENABLED}
      - ORCHESTRATOR_CLIENT_CERT=${ORCHESTRATOR_CLIENT_CERT}
      - ORCHESTRATOR_CLIENT_KEY=${ORCHESTRATOR_CLIENT_KEY}
      - S3_URL=http://minio:9000
      - S3_REGION=us-east-1
      - S3_DIFF_DATA_BUCKET=diff-data
      - S3_ACCESS_KEY=admin
      - S3_SECRET_KEY=abc123456
  webhook:
    depends_on:
      - mongodb
      - zookeeper
      - kafka
      - redis
    deploy:
      restart_policy:
        condition: on-failure
        delay: 3s
        max_attempts: 5
        window: 60s
    build:
      context: .
      dockerfile: ./apps/webhook/Dockerfile
    expose:
      - 8080
    ports:
      - 9005:8080
    environment:
      - NODE_ENV=development
      - PORT=9000
      - DB_TYPE=mongodb
      - DB_URI=${DB_URI}
      - BROKER_TYPE=kafka
      - BROKER_URIS=${BROKER_URIS}
      - KAFKA_CLIENT_ID=webhook
      - KAFKA_CONSUMER_GROUP_ID=webhook-consumer
      - KAFKA_SSL_ENABLED=${KAFKA_SSL_ENABLED}
      - KAFKA_SASL_ENABLED=${KAFKA_SASL_ENABLED}
      - KAFKA_SASL_USERNAME=${KAFKA_SASL_USERNAME}
      - KAFKA_SASL_PASSWORD=${KAFKA_SASL_PASSWORD}
      - REDIS_HOST=${REDIS_HOST}
      - REDIS_PORT=${REDIS_PORT}
      - REDIS_PASSWORD=${REDIS_PASSWORD}
      - REDIS_TLS_ENABLED=${REDIS_TLS_ENABLED}
      - WEBHOOK_PRIVATE_KEY=-----BEGIN PRIVATE KEY-----\nMIIEvAIBADANBgkqhkiG9w0BAQEFAASCBKYwggSiAgEAAoIBAQDP2yBStuVi2fIQvv1tFh0VvyGvZIhLrhA/JoDnO3Cp2psh5UHXssLntj3wQY+eyrDhEPAj0bq9LT8xCBlFKOmv1oojtx0uTNudFTFFgluQA2f4y/91HqCh9QL26lu1mNUx/Tx5NSUlZjdp2gEMD84+8d+eYzbUOzlsqlNHYicHz/o04l1XzEWZ0dLiEaYas4FI9Rlu+aa5oXLS+Mbn6tift+L/EC0hD4V6flRz/HH3kCnYDPOJ/m2UjY22gimvW/aTl2j1WZWYgqyTlIu9YCG548lrOIXFFCwsxHrcwMzM8DoPdKx5HVxR2I1cJ4KhmIgwqBNcP7yuwk0JCNJmiQbNAgMBAAECggEAG4W/326hVrgA0fqAKGrLr3P5/AqbSNjDr6D5DjqJfgGDa3cQWK/ZGAEXwtGOOK/3wNgofA21eimHcFt1Vnoxi0YkpNBb2E7MAPOWl8Ydj/xWJD8Ff0Fux/3fMR5cxgx2emKLmIm9dpjKJfAnFazyxH9BesGst73J1PDZYHPc3YSNQIzP/4F2rhGn7fFkWu06Bsj2nY6/J0L7HLHKAdJ1GvV2K/zoiv2GEsZKvOPa24ofo+eYYfwccZ1+09wnfxuBo1f9Qva80Hc3MTHgiQwG3BVdnmV5KuL+DUX2sqWokfhqEnHrmtaoPK3M0fsU3T6fTiXEnrSK/ectUyKAvCjL/wKBgQD92tZ+exjXiGawIHkBrvTK17kPH8vQYxKvDL6/xB0ggKrL1okyV0aqpQJVB2bW0Qf8zxxpFDCx6gtZ0ML6FU2zfJ0xpG/k1dRELCs9KvH4yyDRkK9Ld2XWDB4XfTTA3y3LuOfOVgLE/PmKSzXFFG0LrcGGgALG4CDaMB3jMFEVWwKBgQDRnMeGw65ETeTz+HPkAnDRb1UBaMyhyGafjq4kALV8m0pR2JVmR/D5OvH/yt65t1IZ6HAbaccIncBfJ3+604wN+URGG2Tmln+hVSdIdTLNhbLsfkBBqbuBWkTPtdrYgXL0nlM47U1UZlvgqQ5y7iXoyOcqsYRETLNl2R1TNWgE9wKBgH8VlDYDmB8mmQnpZ8rQ9Jmrv2hz6YvsXUknH0NPgalo4JhlUY/TI3yAWReKOhCm2tHUOYvdYLdgzMfs+/9ItPp7ExLsGFw+NCLg3dCkdDiyMD7ZqPgl0OSEcngd5U/9KqcHbXzdkEtfvele149PN3wWQ4D7CujXAXtZhUzcPmtrAoGAQ3XVsUWg/FKlcO9xPNycOos+LGnyEc9RV+Cvot6niibgUF8IFhbpMw0JfW1pKRQa1EO+cNQmPlum4fjwXsxestCabIW8f4nIIcAqGGO/qe1xnDM1suxRcFwA8WhxumRO/vNFjXix/ovC3hcKk2qZwMWHwHHJQ8H7qrepfHIfvBkCgYBYrO2h24uke0fVFgy5CJErjV9S7yymPgJBv4LePctisAspnFL83T+NODIZGqb9aq4woYfJAT6BoAKuWGrCOp6rvalb+b7OfhYf74l/fozfYx5NsCqyCucATy6y6tarsk1bfRGoS5Nu/dJxpckKk+6EGPk6PZLQyLtkfkcNylXz0A==\n-----END PRIVATE KEY-----
  #--------------------------------- PROCESSORS --------------------------------------#
  downloader:
    depends_on:
      - minio
    deploy:
      restart_policy:
        condition: on-failure
        delay: 3s
        max_attempts: 5
        window: 60s
      resources:
        limits:
          cpus: '1'
          memory: 1024M
    platform: linux/amd64
    build:
      context: ./apps/processors/downloader
      dockerfile: Dockerfile
    expose:
      - 8080
    ports:
      - 8000:8080
    environment:
      - PORT=8080
      - API_KEYS=${PROCESSOR_API_KEYS}
      - S3_ENDPOINT=${S3_ENDPOINT}
      - S3_REGION=${S3_REGION}
      - S3_DIFF_DATA_BUCKET=${S3_DIFF_DATA_BUCKET}
      - S3_ACCESS_KEY=${S3_ACCESS_KEY}
      - S3_SECRET_KEY=${S3_SECRET_KEY}
  comparer:
    depends_on:
      - minio
    deploy:
      restart_policy:
        condition: on-failure
        delay: 3s
        max_attempts: 5
        window: 60s
      resources:
        limits:
          cpus: '1'
          memory: 512M
    build:
      context: ./apps/processors/comparer
      dockerfile: Dockerfile
    expose:
      - 8080
    ports:
      - 8001:8080
    environment:
      - PORT=8080
      - API_KEYS=${PROCESSOR_API_KEYS}
      - S3_ENDPOINT=${S3_ENDPOINT}
      - S3_REGION=${S3_REGION}
      - S3_DIFF_DATA_BUCKET=${S3_DIFF_DATA_BUCKET}
      - S3_ACCESS_KEY=${S3_ACCESS_KEY}
      - S3_SECRET_KEY=${S3_SECRET_KEY}
  loader:
    depends_on:
      - minio
      - postgresql
    deploy:
      restart_policy:
        condition: on-failure
        delay: 3s
        max_attempts: 5
        window: 60s
      resources:
        limits:
          cpus: '1'
          memory: 1024M
    build:
      context: ./apps/processors/loader
      dockerfile: Dockerfile
    expose:
      - 8080
    ports:
      - 8002:8080
    environment:
      - GOGC=100
      # - GOMEMLIMIT=400MiB
      - PORT=8080
      - API_KEYS=${PROCESSOR_API_KEYS}
      - S3_ENDPOINT=${S3_ENDPOINT}
      - S3_REGION=${S3_REGION}
      - S3_DIFF_DATA_BUCKET=${S3_DIFF_DATA_BUCKET}
      - S3_ACCESS_KEY=${S3_ACCESS_KEY}
      - S3_SECRET_KEY=${S3_SECRET_KEY}
      - DB_TYPE=postgres
      # - DB_HOST=postgresql
      # - DB_PORT=5432
      # - DB_USER=admin
      # - DB_PASSWORD=abc123456
      # - DB_NAME=starion-sync
      # - DB_SSL_MODE=disable
      - DB_URI=${DEST_DB_URI}
      - POSTGRES_INSERT_BATCH_SIZE=${POSTGRES_INSERT_BATCH_SIZE}
  #--------------------------------- TRIGGERS --------------------------------------#
  cron-trigger:
    depends_on:
      - mongodb
      - zookeeper
      - kafka
      - redis
    deploy:
      restart_policy:
        condition: on-failure
        delay: 3s
        max_attempts: 5
        window: 60s
    build:
      context: .
      dockerfile: ./apps/triggers/cron/Dockerfile
    expose:
      - 8080
    ports:
      - 8003:8080
    environment:
      - NODE_ENV=development
      - PORT=8080
      - DB_TYPE=mongodb
      - DB_URI=${DB_URI}
      - BROKER_TYPE=kafka
      - BROKER_URIS=${BROKER_URIS}
      - KAFKA_CLIENT_ID=cron-trigger
      - KAFKA_CONSUMER_GROUP_ID=cron-trigger
      - KAFKA_SSL_ENABLED=${KAFKA_SSL_ENABLED}
      - KAFKA_SASL_ENABLED=${KAFKA_SASL_ENABLED}
      - KAFKA_SASL_USERNAME=${KAFKA_SASL_USERNAME}
      - KAFKA_SASL_PASSWORD=${KAFKA_SASL_PASSWORD}
      - ORCHESTRATOR_ADDRESS=${ORCHESTRATOR_ADDRESS}
      - ORCHESTRATOR_WORKER_TASKQUEUE=cron-trigger
      - ORCHESTRATOR_DEFAULT_TASKQUEUE=cron-trigger
      - REDIS_HOST=${REDIS_HOST}
      - REDIS_PORT=${REDIS_PORT}
      - REDIS_PASSWORD=${REDIS_PASSWORD}
      - REDIS_TLS_ENABLED=${REDIS_TLS_ENABLED}
  webhook-trigger:
    depends_on:
      - mongodb
      - zookeeper
      - kafka
      - redis
    deploy:
      restart_policy:
        condition: on-failure
        delay: 3s
        max_attempts: 5
        window: 60s
    build:
      context: .
      dockerfile: ./apps/triggers/webhook/Dockerfile
    expose:
      - 8080
    ports:
      - 8004:8080
    environment:
      - NODE_ENV=development
      - PORT=8080
      - DB_TYPE=mongodb
      - DB_URI=${DB_URI}
      - BROKER_TYPE=kafka
      - BROKER_URIS=${BROKER_URIS}
      - KAFKA_CLIENT_ID=webhook-trigger
      - KAFKA_CONSUMER_GROUP_ID=webhook-trigger
      - KAFKA_SSL_ENABLED=${KAFKA_SSL_ENABLED}
      - KAFKA_SASL_ENABLED=${KAFKA_SASL_ENABLED}
      - KAFKA_SASL_USERNAME=${KAFKA_SASL_USERNAME}
      - KAFKA_SASL_PASSWORD=${KAFKA_SASL_PASSWORD}
      - REDIS_HOST=${REDIS_HOST}
      - REDIS_PORT=${REDIS_PORT}
      - REDIS_PASSWORD=${REDIS_PASSWORD}
      - REDIS_TLS_ENABLED=${REDIS_TLS_ENABLED}
      - GOOGLE_CLIENT_ID=${GOOGLE_CLIENT_ID}
      - GOOGLE_CLIENT_SECRET=${GOOGLE_CLIENT_SECRET}
      - WEBHOOK_TRIGGER_BASE_URL=${WEBHOOK_TRIGGER_BASE_URL}
  #-------------------------------------- HARMONIES ---------------------------------#
  rate-limiter:
    depends_on:
      - redis
    deploy:
      restart_policy:
        condition: on-failure
        delay: 3s
        max_attempts: 5
        window: 60s
    build:
      context: ./harmonies/rate-limiter
      dockerfile: Dockerfile
    expose:
      - 8080
    environment:
      - NODE_ENV=development
      - PORT=8080
      - REDIS_HOST=${REDIS_HOST}
      - REDIS_PORT=${REDIS_PORT}
      - REDIS_PASSWORD=${REDIS_PASSWORD}
      - REDIS_TLS_ENABLED=${REDIS_TLS_ENABLED}
  #--------------------------------- DATABASE ---------------------------------------#
  mongodb:
    restart: on-failure
    build:
      context: .
      dockerfile: ./init/mongodb.Dockerfile
    expose:
      - 27017
    ports:
      - 27017:27017
    volumes:
      - mongo:/data/db
    healthcheck:
      test: test $$(echo 'rs.initiate({_id':' "rs0", members':' [{_id':' 1, "host"':' "localhost':'27017"}]}) || rs.status().ok' | mongosh -u $${MONGO_INITDB_ROOT_USERNAME} -p $${MONGO_INITDB_ROOT_PASSWORD} --quiet) -eq 1
      interval: 10s
      start_period: 30s
    environment:
      - MONGO_INITDB_ROOT_USERNAME=admin
      - MONGO_INITDB_ROOT_PASSWORD=abc123456
      - MONGO_INITDB_DATABASE=starion-sync
  postgresql:
    container_name: postgresql
    image: postgres:15.3-alpine3.18
    expose:
      - 5432
    ports:
      - 5432:5432
    volumes:
      - postgresql:/var/lib/postgresql/data
    environment:
      - POSTGRES_USER=admin
      - POSTGRES_PASSWORD=abc123456
      - POSTGRES_DB=starion-sync
  pgadmin:
    depends_on:
      - postgresql
    restart: unless-stopped
    image: dpage/pgadmin4:7.4
    ports:
      - 3003:80
    volumes:
      - pgadmin:/var/lib/pgadmin
      - ./init/pgadmin-servers.json:/pgadmin4/servers.json # preconfigured servers/connections
      - ./init/pgpass:/pgpass # passwords for the connections in this file
    environment:
      - PGADMIN_DEFAULT_EMAIL=admin@starion.io
      - PGADMIN_DEFAULT_PASSWORD=abc123456
      - PGADMIN_CONFIG_SERVER_MODE=False
  #--------------------------------- KAFKA ---------------------------------------#
  zookeeper:
    # restart: always
    image: confluentinc/cp-zookeeper:7.4.0
    expose:
      - 2181
    ports:
      - 2181:2181
    volumes:
      - zookeeper-data:/var/lib/zookeeper/data
      - zookeeper-log:/var/lib/zookeeper/log
    environment:
      - ALLOW_ANONYMOUS_LOGIN=yes
      - ZOOKEEPER_CLIENT_PORT=2181
      - ZOOKEEPER_TICK_TIME=2000
  kafka:
    depends_on:
      - zookeeper
    # restart: always
    image: confluentinc/cp-kafka:7.4.0
    expose:
      - 9092
      - 29092
    ports:
      - 9092:9092
    volumes:
      - kafka:/var/lib/kafka/data
    environment:
      - KAFKA_BROKER_ID=1
      - KAFKA_ZOOKEEPER_CONNECT=zookeeper:2181
      - KAFKA_LISTENER_SECURITY_PROTOCOL_MAP=PLAINTEXT:PLAINTEXT,PLAINTEXT_INTERNAL:PLAINTEXT
      - KAFKA_ADVERTISED_LISTENERS=PLAINTEXT://localhost:9092,PLAINTEXT_INTERNAL://kafka:29092
      - KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR=1
      - KAFKA_TRANSACTION_STATE_LOG_MIN_ISR=1
      - KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR=1
  kafka-ui:
    depends_on:
      - kafka
    container_name: kafka-ui
    image: provectuslabs/kafka-ui:latest
    ports:
      - 3000:8080
    volumes:
      - ./init/kui-config.yml:/etc/kafkaui/dynamic_config.yaml
    environment:
      DYNAMIC_CONFIG_ENABLED: true
  #----------------------------------- REDIS ----------------------------------------#
  redis:
    image: redis:6.2-alpine
    expose:
      - 6379
    ports:
      - 6379:6379
    command: redis-server --save 20 1 --loglevel warning --requirepass abc123456
    volumes:
      - redis:/data
  #--------------------------------- ORCHESTRATOR (TEMPORAL) ---------------------------------------#
  temporal:
    depends_on:
      - postgresql
    image: temporalio/auto-setup:1.22.0
    expose:
      - 7233
    ports:
      - 7233:7233
    labels:
      kompose.volume.type: configMap
    volumes:
      - ./init/temporal-config.yml:/etc/temporal/config/dynamicconfig/development-sql.yaml
    environment:
      - DB=postgres12
      - DB_PORT=5432
      - POSTGRES_USER=admin
      - POSTGRES_PWD=abc123456
      - POSTGRES_SEEDS=postgresql
      - DYNAMIC_CONFIG_FILE_PATH=config/dynamicconfig/development-sql.yaml
  temporal-ui:
    depends_on:
      - temporal
    ports:
      - 3001:8080
    image: temporalio/ui:2.17.1
    environment:
      - TEMPORAL_ADDRESS=temporal:7233
      - TEMPORAL_CORS_ORIGINS=http://localhost:3001
  temporal-admin-tools:
    restart: 'no'
    depends_on:
      - temporal
    image: temporalio/admin-tools:1.22.0
    stdin_open: true
    tty: true
    entrypoint: bash
    command: '/etc/temporal/init.sh'
    volumes:
      - ./init/temporal-init.sh:/etc/temporal/init.sh
    environment:
      - TEMPORAL_ADDRESS=temporal:7233
      - TEMPORAL_CLI_ADDRESS=temporal:7233
  #--------------------------------- MINIO ---------------------------------------#
  minio:
    container_name: minio
    image: minio/minio
    expose:
      - 9000
    ports:
      - 3002:9001
    entrypoint: sh
    command: -c 'mkdir -p /data/diff-data && minio server --console-address ":9001" /data'
    volumes:
      - minio:/data
    environment:
      - MINIO_ROOT_USER=admin
      - MINIO_ROOT_PASSWORD=abc123456
volumes:
  mongo:
  mysql:
  redis:
  zookeeper-log:
  zookeeper-data:
  kafka:
  postgresql:
  pgadmin:
  minio:
